# Classifying the kickstarter projects as success or failure
In this project, I built and tested 6 supervised machine learning algorithms including logistic regression, k-nearest neighbors, classification tree, random forest, gradient boosting and artificial neural network (ANN), to predict the success of kickstarter projects.

ğŸŒ About Kickstarter:
Kickstarter is a platform where creators share their project visions with the communities that will come together to fund them. 

ğŸ’¼ Business Value:
For the Kickstarter's managament, predicting success means planning ahead. My model helps in predicting the success of projects, guiding staff picks, to select the projects worthy of the spotlight, which can increase the visibility and popularity of the platform.

ğŸ”„ Process Overview:
I followed these steps to build and test the models:
1. Data Preprocessing:
   I began with data exploration, identified the dominance of US (71%) in column ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘Ÿğ‘¦, so I replaced other countries with label 'Non-US'. Then, I dropped ğ‘›ğ‘ğ‘šğ‘’_ğ‘™ğ‘’ğ‘› and ğ‘ğ‘™ğ‘¢ğ‘Ÿğ‘_ğ‘™ğ‘’ğ‘›, keeping
   the cleaned versions, handled a strong correlation between pledged and ğ‘¢ğ‘ ğ‘‘_ğ‘ğ‘™ğ‘’ğ‘‘ğ‘”ğ‘’ğ‘‘, created a new column ğ‘”ğ‘œğ‘ğ‘™_ğ‘¢ğ‘ ğ‘‘ by multiplying ğ‘”ğ‘œğ‘ğ‘™ and ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘_ğ‘¢ğ‘ ğ‘‘_ğ‘Ÿğ‘ğ‘¡ğ‘’, addressed missing values in ğ‘ğ‘ğ‘¡ğ‘’ğ‘”ğ‘œğ‘Ÿğ‘¦, and excluded observations with ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘’ other than 'successful' or 'failure'.
2. Model Preparation and Feature Engineering:
   - I excluded irrelevant features such as ğ‘–ğ‘‘ and ğ‘›ğ‘ğ‘šğ‘’, hourly details, original date columns, and weekday columns.
   - The goal of this project is to classify a new project as successful or not, based on the information available at the moment when the project owner submits the project. So, the model should only use the predictors that are available at that time. Hence, I removed 12 columns not available at project submission, including ğ‘ğ‘™ğ‘’ğ‘‘ğ‘”ğ‘’ğ‘‘, ğ‘¢ğ‘ ğ‘‘_ğ‘ğ‘™ğ‘’ğ‘‘ğ‘”ğ‘’ğ‘‘, ğ‘‘ğ‘–ğ‘ ğ‘ğ‘ğ‘™ğ‘’_ğ‘ğ‘œğ‘šğ‘šğ‘¢ğ‘›ğ‘–ğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘›, ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘’_ğ‘hğ‘ğ‘›ğ‘”ğ‘’ğ‘‘_ğ‘ğ‘¡, ğ‘ ğ‘¡ğ‘ğ‘“ğ‘“_ğ‘ğ‘–ğ‘ğ‘˜ and ğ‘ ğ‘ğ‘œğ‘¡ğ‘™ğ‘–ğ‘”hğ‘¡.
   - After separating the target 'state', I created dummies from 17 features, resulting in 39 predictors, and eliminated 3 having a correlation of 0.80 or higher.
4. Model Building:
   After splitting the dataset, I trained six classification models, and chose accuracy as the primary performance metric to predict true success and failure. The Gradient Boosting (GBT) Algorithm emerged as the top performer with the highest accuracy at 75.30%. 
ğŸ’¡ What is GBT? It generates a large number of trees, and through its sequential tree growth (every time learning from the tree one before it), it places greater emphasis on observations with large errors, making it well-suited for this context.

ğŸ‰ Conclusion:
I applied the GBT model to predict the state of projects in kickstarter_grading_df, and achieved an accuracy of 74.34%, confirming its effectiveness as the best model.
