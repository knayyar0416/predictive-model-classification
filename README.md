# Classifying the kickstarter projects as success or failure
In this project, I built and tested 6 supervised machine learning algorithms including logistic regression, k-nearest neighbors, classification tree, random forest, gradient boosting and artificial neural network (ANN), to predict the success of kickstarter projects.

## ğŸŒ About Kickstarter:
[Kickstarter](https://www.kickstarter.com/) is a platform where creators share their project visions with the communities that will come together to fund them. 

## ğŸ’¼ Business Value:
For Kickstarter's managament, predicting success means planning ahead. My model helps in predicting the success of projects, guiding staff picks, to select the projects worthy of the spotlight, which can increase the visibility and popularity of the platform.

## ğŸ› ï¸ Process Overview:
I followed these steps to build and test the models:
1. ğŸ“Š Data Exploration:
   - Explored the data and found that US projects accounted for 71% of the data, so I grouped the other countries as â€˜Non-USâ€™.
2. ğŸ§¹ Data Cleansing:
   - Dropped ğ‘›ğ‘ğ‘šğ‘’_ğ‘™ğ‘’ğ‘› and ğ‘ğ‘™ğ‘¢ğ‘Ÿğ‘_ğ‘™ğ‘’ğ‘›, keeping the cleaned versions.
   - Handled a strong correlation between pledged and ğ‘¢ğ‘ ğ‘‘_ğ‘ğ‘™ğ‘’ğ‘‘ğ‘”ğ‘’ğ‘‘, by dropping the former.
   - Created a new column ğ‘”ğ‘œğ‘ğ‘™_ğ‘¢ğ‘ ğ‘‘ by multiplying ğ‘”ğ‘œğ‘ğ‘™ and ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘–ğ‘_ğ‘¢ğ‘ ğ‘‘_ğ‘Ÿğ‘ğ‘¡ğ‘’.
   - Addressed missing values in ğ‘ğ‘ğ‘¡ğ‘’ğ‘”ğ‘œğ‘Ÿğ‘¦, and excluded observations with ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘’ other than 'successful' or 'failure'.
3. ğŸ› ï¸ Feature Engineering:
   - Excluded irrelevant features such as ğ‘–ğ‘‘ and ğ‘›ğ‘ğ‘šğ‘’, hourly details, original date columns, and weekday columns.
   - The goal of this project is to classify a new project as successful or not, based on the information available at the moment when the project owner submits the project. So, the model should only use the predictors that are available at that time. Hence, I removed 12 columns not available at project submission, including ğ‘ğ‘™ğ‘’ğ‘‘ğ‘”ğ‘’ğ‘‘, ğ‘¢ğ‘ ğ‘‘_ğ‘ğ‘™ğ‘’ğ‘‘ğ‘”ğ‘’ğ‘‘, ğ‘‘ğ‘–ğ‘ ğ‘ğ‘ğ‘™ğ‘’_ğ‘ğ‘œğ‘šğ‘šğ‘¢ğ‘›ğ‘–ğ‘ğ‘ğ‘¡ğ‘–ğ‘œğ‘›, ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘’_ğ‘hğ‘ğ‘›ğ‘”ğ‘’ğ‘‘_ğ‘ğ‘¡, ğ‘ ğ‘¡ğ‘ğ‘“ğ‘“_ğ‘ğ‘–ğ‘ğ‘˜ and ğ‘ ğ‘ğ‘œğ‘¡ğ‘™ğ‘–ğ‘”hğ‘¡.
   - After separating the target ğ‘ ğ‘¡ğ‘ğ‘¡ğ‘’, I created dummies from 17 features, resulting in 39 predictors, and eliminated 3 having a correlation of 0.80 or higher. 
4. ğŸ¤– Model Training: After splitting the dataset, I trained six classification models, and chose accuracy as the primary performance metric to predict true success and failure. I also tested models by using LASSO features and PCA components, but since those gave me a lower accuracy for RF and GBT, I chose our initial list of features as final model.
![image](model-performance.png)
6. ğŸš€ Top Performer: The Gradient Boosting (GBT) Algorithm emerged as the top performer with the highest accuracy at 75.30%. 
   ğŸ’¡ GBT generates a large number of trees, and through its sequential tree growth (every time learning from the tree one before it), it places greater emphasis on observations with large errors, making it well-suited for this context.

## ğŸ‰ Conclusion:
I applied the GBT model to predict the state of projects in kickstarter_grading_df.xlsx, and achieved an accuracy of 74.34%, confirming its effectiveness as the best model.
